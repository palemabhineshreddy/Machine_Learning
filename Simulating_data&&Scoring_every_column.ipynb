{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simulating_data&&Scoring_every_column.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8luavX5as5IodCB7LCBKF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palemabhineshreddy/Machine_Learning/blob/master/Simulating_data%26%26Scoring_every_column.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQvIOMkBS9K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Question 1 --- (A---Simulating data)\n",
        "\n",
        "-----#The below code only represents the dimensionality of data without considering the explained variance------\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 25)  #Reducing the dimensionality of the data from 5000 to 25\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "\n",
        "------#The below code represents the dimensionality of data considering Explained variance-----\n",
        "\n",
        "# Applying  PCA \n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA().fit(X)     #X-the input data \n",
        "\n",
        "#Plotting the Cumulative Summation of the Explained Variance(for finding the n_components  i.e feature extraction)\n",
        "plt.figure()\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Variance (%)')             #for each component\n",
        "plt.title('Companies Dataset Explained Variance')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#we need to check how many features will give 99% of the variance from the plot,In according to that we have to select n_components i.e consider her 25 features \n",
        "\n",
        "#Fitting PCA to the data\n",
        "pca = PCA(n_components = 25)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Question 1 ----  (B--Scoring every column)\n",
        "#Backward Elimination with p-values and Adjusted R-squared(I will approach this method for finding which columns will be useful for the model prediction)\n",
        "\n",
        "\n",
        "import statsmodels.formula.api as sm\n",
        "def backwardElimination(x, SL):\n",
        "    numVars = len(x[0])\n",
        "    temp = np.zeros((1000000,5000)).astype(int)\n",
        "    for i in range(0, numVars):\n",
        "        regressor_OLS = sm.OLS(y, x).fit()\n",
        "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
        "        adjR_before = regressor_OLS.rsquared_adj.astype(float)\n",
        "        if maxVar > SL:\n",
        "            for j in range(0, numVars - i):\n",
        "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
        "                    temp[:,j] = x[:, j]\n",
        "                    x = np.delete(x, j, 1)\n",
        "                    tmp_regressor = sm.OLS(y, x).fit()\n",
        "                    adjR_after = tmp_regressor.rsquared_adj.astype(float)\n",
        "                    if (adjR_before >= adjR_after):\n",
        "                        x_rollback = np.hstack((x, temp[:,[0,j]]))\n",
        "                        x_rollback = np.delete(x_rollback, j, 1)\n",
        "                        print (regressor_OLS.summary())\n",
        "                        return x_rollback\n",
        "                    else:\n",
        "                        continue\n",
        "    regressor_OLS.summary()\n",
        "    return x\n",
        " \n",
        "SL = 0.05     # SL - Significance level\n",
        "X_opt = X[:, [0, 1, 2, 3, 4, 5,.......5000]]    #input data\n",
        "X_Modeled = backwardElimination(X_opt, SL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}